{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shahzaib\\miniconda3\\envs\\torch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "# import adam\n",
    "from torch.optim import Adam\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"yangheng/deberta-v3-base-absa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shahzaib\\miniconda3\\envs\\torch\\Lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for knowledgator/events_classification_biotech contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/knowledgator/events_classification_biotech\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('knowledgator/events_classification_biotech') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Ultra Health Initiates Cannabis Coverage for Behavioral',\n",
       " 'content': 'Ultra Health Initiates Cannabis Coverage for Behavioral Health Services\\nNew Mexicos #1 cannabis company requests insurer confirmation to eliminate cannabis cost-sharing\\nFebruary 21, 2022 12:47 ET\\n| Source:\\nUltra Health\\nScottsdale, Arizona, UNITED STATES\\nALBUQUERQUE, N.M., Feb.  21, 2022  (GLOBE NEWSWIRE) -- Ultra Health, New Mexicos #1 Cannabis Company, recently sent a\\nletter\\nto New Mexicos prominent health insurers and New Mexico state departments to seek confirmation from insurers for cannabis coverage as a behavioral health service.\\nThe communication is a response to a recent law that eliminated all cost-sharing and any out-of-pocket costs for behavioral health services and medications.\\nOn January 1, 2022,\\nSenate Bill 317\\nbecame effective to make mental and behavioral health services more affordable for New Mexicans.\\nThe legislation expanded the definition of behavioral health services to cover several treatment options including professional and ancillary services for the treatment, habilitation, prevention and identification of mental illnesses, substance abuse disorders and trauma spectrum disorders, including inpatient, detoxification, residential treatment, and partial hospitalization, intensive outpatient therapy, outpatient and all medications, including brand-name pharmacy drugs when generics are unavailable, (emphasis added).\\nCurrently, medical cannabis is a statutorily approved medication for a variety of behavioral health disorders including post-traumatic stress disorder, opioid use disorder, severe anorexia, and Parkinsons disease under the\\nLynn and Erin Compassionate Use Act\\nNearly\\n73,000\\nNew Mexicans of the total 130,000 Medical Cannabis Program enrollees currently qualify for medical cannabis treatment under behavioral health diagnoses.\\nUltra Health acknowledges that the idea of health insurers paying for medical cannabis may seem novel at first blush, the six-page\\nletter\\nstates. However, as Ultra Health will discuss below, it is actually a rational, reasonable notion when considered in light of other New Mexico law. New Mexico already requires workers compensation insurers to pay for medical cannabis, and New Mexico already treats medical cannabis the same as conventional prescription medications. The fact that health insurers shouldand willpay for medical cannabis is not revolutionary at this point. It is the next logical step, and it is a small step, not a giant leap.\\nInsurers currently pay for medical cannabis under New Mexicos Workers Compensation Act, which\\nallows\\ninjured workers to use and be reimbursed for medical cannabis when deemed reasonable and necessary care.\\nCannabis coverage is also a validated service in other countries.\\nIn Canada, insurers currently pay for medical cannabis through\\nhealth benefit plans',\n",
       " 'target organization': 'Behavioral Dimensions',\n",
       " 'all_labels': ['other'],\n",
       " 'all_labels_concat': 'other',\n",
       " 'label 1': 23,\n",
       " 'label 2': None,\n",
       " 'label 3': None,\n",
       " 'label 4': None,\n",
       " 'label 5': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"['food' , 'place']\"\n",
    "\n",
    "def string2array(string):\n",
    "    new_string = string[1:-1]\n",
    "    new_string = new_string.strip()\n",
    "    new_string = new_string.replace(\" \", \"\")\n",
    "    new_string = new_string.replace(\"'\", \"\")\n",
    "    return new_string.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = string2array(\"['food' , 'place']\")\n",
    "print(type(out))\n",
    "print(type(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_terms = data['Aspects'].tolist()\n",
    "aspect_labels = []\n",
    "# print(aspect_terms)\n",
    "for item in aspect_terms:\n",
    "    arr = string2array(item)\n",
    "    for aspect in arr:\n",
    "        aspect_labels.append(aspect)\n",
    "\n",
    "aspect_labels = list(set(aspect_labels))\n",
    "print(aspect_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_labels = ['negative', 'positive', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot(aspect, sentiment):\n",
    "    encoding = np.zeros((1,28))\n",
    "    aspect_index = aspect_labels.index(aspect)*4\n",
    "    encoding[0][aspect_index]= 1\n",
    "    encoding[0][sentiment_labels.index(sentiment)+aspect_index+1] = 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHot(\"place\", \"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiOneHot(aspects, sentiments):\n",
    "    assert(len(aspects) == len(sentiments))\n",
    "    encoding = np.zeros((1,28))\n",
    "    for i in range(len(aspects)):\n",
    "        aspect_index = aspect_labels.index(aspects[i])*4\n",
    "        encoding[0][aspect_index]= 1\n",
    "        encoding[0][sentiment_labels.index(sentiments[i])+aspect_index+1] = 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiOneHot([\"price\",\"place\"],[\"positive\",\"negative\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for aspect in aspect_labels:\n",
    "    classes.append(aspect)\n",
    "    for sentiment in sentiment_labels:\n",
    "        classes.append(aspect + \"_\" + sentiment)\n",
    "\n",
    "print(classes)\n",
    "class2id = {classes[i]:i for i in range(len(classes))}\n",
    "id2class = {i:classes[i] for i in range(len(classes))}\n",
    "print(class2id)\n",
    "print(id2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizedString2Array(arr):\n",
    "    # now we have a list of strings like [\"['food' , 'place']\", \"['food' , 'place']\"]\n",
    "    # we need to convert this into a list of lists like [['food', 'place'], ['food', 'place']]\n",
    "    out = []\n",
    "    for item in arr:\n",
    "        out.append(string2array(item))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineClassesVectorized(aspects, sentiments):\n",
    "    assert(type(aspects) == list)\n",
    "    combined = []\n",
    "    for example_idx in range(len(aspects)):\n",
    "        aspect = aspects[example_idx]\n",
    "        sentiment = sentiments[example_idx]\n",
    "        combined.append([])\n",
    "        for idx in range(len(aspect)):\n",
    "            combined[example_idx].append(aspect[idx])\n",
    "            combined[example_idx].append(aspect[idx] + \"_\" + sentiment[idx])\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineClasses(aspects, sentiments):\n",
    "    assert(len(aspects) == len(sentiments))\n",
    "    combined = []\n",
    "    for idx in range(len(aspects)):\n",
    "        combined.append(aspects[idx])\n",
    "        combined.append(aspects[idx] + \"_\" + sentiments[idx])\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = combineClassesVectorized([[\"price\",\"place\"],[\"price\",\"place\"]],[[\"positive\",\"negative\"],[\"positive\",\"negative\"]])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatset Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = SentimentDataset('sentiment.csv')\n",
    "dataset = load_dataset('csv', data_files='sentiment.csv', split='train')\n",
    "# create data splits with 0.8 and 0.2\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_classes = combineClasses(string2array(dataset[\"train\"][0][\"Aspects\"]), string2array(dataset[\"train\"][0][\"Sentiment\"]))\n",
    "print(out_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0. for i in range(len(classes))]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in out_classes:\n",
    "        label_id = class2id[label]\n",
    "        labels[label_id] = 1.\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_function(examples):\n",
    "#     combined_classes = combineClasses(vectorizedString2Array(examples[\"Aspects\"]),vectorizedString2Array(examples[\"Sentiment\"]))\n",
    "\n",
    "#     for example in examples:\n",
    "#         example[\"combined_classes\"] = combined_classes\n",
    "#         labels = [0. for i in range(len(classes))]\n",
    "#         for label in example[\"combined_classes\"]:\n",
    "#             label_id = class2id[label]\n",
    "#             labels[label_id] = 1.\n",
    "#         example[\"labels\"] = labels\n",
    "        \n",
    "#     # tokenize the examples\n",
    "#     return tokenizer(examples[\"Reviews\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "#     # return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    text = example[\"Review\"]\n",
    "    combined_classes = combineClasses(string2array(example[\"Aspects\"]), string2array(example[\"Sentiment\"]))\n",
    "    labels = [0. for i in range(len(classes))]\n",
    "    for label in combined_classes:\n",
    "        # print(label)\n",
    "        label_id = class2id[label]\n",
    "        labels[label_id] = 1.\n",
    "    example[\"labels\"] = labels\n",
    "    example = tokenizer(text, truncation=True)\n",
    "    \n",
    "    return example\n",
    "    # return tokenizer(example[\"Review\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=False)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def sigmoid(x):\n",
    "   return 1/(1 + np.exp(-x))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "   predictions, labels = eval_pred\n",
    "   predictions = sigmoid(predictions)\n",
    "   predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "   return clf_metrics.compute(predictions=predictions, references=labels.astype(int).reshape(-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#    checkpoint, num_labels=len(classes),\n",
    "#            id2label=id2class, label2id=class2id,\n",
    "#                        problem_type = \"multi_label_classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchinfo\n",
    "# torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = 1\n",
    "# base_dir = \"runs/exp_\" + str(exp)\n",
    "# training_args = TrainingArguments(\n",
    "\n",
    "#    output_dir=base_dir+\"/model\",\n",
    "#    learning_rate=2e-5,\n",
    "#    per_device_train_batch_size=3,\n",
    "#    per_device_eval_batch_size=3,\n",
    "#    num_train_epochs=2,\n",
    "#    weight_decay=0.01,\n",
    "#    evaluation_strategy=\"epoch\",\n",
    "#    save_strategy=\"epoch\",\n",
    "#    load_best_model_at_end=True,\n",
    "#    logging_dir=base_dir+\"/logs\",\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "\n",
    "#    model=model,\n",
    "#    args=training_args,\n",
    "#    train_dataset=tokenized_dataset[\"train\"],\n",
    "#    eval_dataset=tokenized_dataset[\"test\"],\n",
    "#    tokenizer=tokenizer,\n",
    "#    data_collator=data_collator,\n",
    "#    compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model_path = \"runs/checkpoint-4102\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The final blow was when the waiter brought us the check before we had even finished dessert--never mind that the only reason we were taking a long time to finish the meal was because of the extreme delay in the service of our food.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "predictions = (torch.sigmoid(logits) > threshold).int()\n",
    "print(predictions)\n",
    "print([id2class[i] for i in range(len(classes)) if predictions[0][i] == 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model=model, threshold=0.3):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predictions = (torch.sigmoid(logits) > threshold).int()\n",
    "    # print(text)\n",
    "    #output cleanup\n",
    "    for i in range(len(predictions)):\n",
    "        # if any aspect is not predicted, its sentiments should not be predicted\n",
    "        if i%4 == 0:\n",
    "            if predictions[0][i] == 0:\n",
    "                i = i+4\n",
    "            else:\n",
    "                # only one sentiment should be predicted if aspect is predicted\n",
    "                continue\n",
    "    outputs = [id2class[i] for i in range(len(classes)) if predictions[0][i] == 1]\n",
    "    aspects = [item for item in outputs if \"_\" not in item]\n",
    "    sentiments = [item.split(\"_\")[1] for item in outputs if \"_\" in item]\n",
    "    return aspects, sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects, sentiments = predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aspects)\n",
    "print(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_without_tokenizer(tokens, model=model, threshold=0.3):\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tokens).logits\n",
    "    predictions = (torch.sigmoid(logits) > threshold).int()\n",
    "    # print(text)\n",
    "\n",
    "    #output cleanup\n",
    "    for i in range(len(predictions)):\n",
    "        # if any aspect is not predicted, its sentiments should not be predicted\n",
    "        if i%4 == 0:\n",
    "            if predictions[0][i] == 0:\n",
    "                i = i+4\n",
    "            else:\n",
    "                # only one sentiment should be predicted if aspect is predicted\n",
    "                continue\n",
    "            \n",
    "\n",
    "\n",
    "    outputs = [id2class[i] for i in range(len(classes)) if predictions[0][i] == 1]\n",
    "    aspects = [item for item in outputs if \"_\" not in item]\n",
    "    sentiments = [item.split(\"_\")[1] for item in outputs if \"_\" in item]\n",
    "    return aspects, sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dataset = load_dataset('csv', data_files='sample_submission.csv', split='train')\n",
    "sub_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings = 0\n",
    "for i in range(len(sub_dataset)):\n",
    "    text = sub_dataset[i][\"Review\"]\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n",
    "    aspects, sentiments = pred_without_tokenizer(tokens, threshold=0.2)\n",
    "    # print(text)\n",
    "    # if length of aspects and sentiments are not same, raise a warning\n",
    "    if len(aspects) != len(sentiments):\n",
    "        print(\"Warning: Length of aspects and sentiments are not same, truncating\")\n",
    "        warnings += 1\n",
    "        # drop the last item if length of aspects and sentiments are not same\n",
    "        if len(aspects) > len(sentiments):\n",
    "            aspects = aspects[:-1]\n",
    "        else:\n",
    "            sentiments = sentiments[:-1]\n",
    "        print(aspects)\n",
    "        print(sentiments)\n",
    "    \n",
    "    submission[\"Aspects\"][i] = aspects\n",
    "    submission[\"Sentiment\"][i] = sentiments\n",
    "\n",
    "print(warnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add blank lists to the empty cells\n",
    "submission.fillna(value=\"[\"\",\"\"]\", inplace=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_interpret import MultiLabelClassificationExplainer\n",
    "cls_explainer = MultiLabelClassificationExplainer(model, tokenizer)\n",
    "word_attributions = cls_explainer(sub_dataset[0][\"Review\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.dumps(word_attributions)\n",
    "# save json to file\n",
    "with open('word_attributions.json', 'w') as f:\n",
    "    json.dump(word_attributions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occlusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_occluded_samples(x, y):\n",
    "    new_test_x = []\n",
    "    new_test_y = []\n",
    "    for i in range(len(x)):\n",
    "        full_emb = x[i]\n",
    "        label = y[i]\n",
    "        new_test_x.append(full_emb)\n",
    "        new_test_y.append(label)\n",
    "        for j in range(len(full_emb)):\n",
    "            # samples with one of chunks occluded\n",
    "            emb_occluded = []\n",
    "            for k in range(len(full_emb)):\n",
    "                if(k==j):\n",
    "                    emb_occluded.append(np.zeros(768))\n",
    "                else:\n",
    "                    emb_occluded.append(full_emb[k])\n",
    "\n",
    "            new_test_x.append(emb_occluded)\n",
    "            new_test_y.append(label)\n",
    "    return new_test_x, new_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_x, new_test_y = make_occluded_samples(dataset[\"Review\"], dataset[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
